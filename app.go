package main

import (
	"flag"
	"fmt"
	"os"
	"sort"
	"strings"
	"time"

	log "github.com/Sirupsen/logrus"
	"github.com/briandowns/spinner"
	"github.com/natdm/goflow/generate"
	"github.com/natdm/goflow/parse"
)

func main() {
	start := time.Now()

	spin := spinner.New(spinner.CharSets[35], time.Second/3)
	spin.Color("green")

	in := flag.String("dir", "./", "dir is to specify what folder to parse types from")
	file := flag.String("file", "-", "file is to parse a single file. Will override a directory")
	out := flag.String("out", "./", "dir is to specify what folder to parse types to")
	recursive := flag.Bool("r", true, "to recursively ascend all folders in dir")
	flag.Usage = usage
	flag.Parse()

	p := parse.New(*recursive)
	spin.Start()
	if *file != "-" {
		if !strings.HasSuffix(*file, ".go") {
			log.Error("the file passed in is not a go file.")
			os.Exit(1)
		}
		p.Files = append(p.Files, *file)
		if err := p.ParseFiles(); err != nil {
			log.WithError(err).Fatalln("error parsing file")
		}
	} else {
		if err := p.ParseDir(*in); err != nil {
			log.WithError(err).Fatalln("error parsing directory")
		}
		if err := p.ParseFiles(); err != nil {
			log.WithError(err).Fatalln("error parsing directory")
		}
	}

	generate.RemoveUnexported(p.Mappings)
	for k, v := range p.Mappings {
		generate.UpdateTypes(k, v)
		generate.UpdateTags(v)
	}

	for k := range p.BaseMappings {
		p.BaseMappings[k] = parse.Field{
			Type:     generate.UpdateType(p.BaseMappings[k].Type),
			Name:     p.BaseMappings[k].Name,
			Comment:  p.BaseMappings[k].Comment,
			JSONTags: p.BaseMappings[k].JSONTags,
		}
	}

	// Try to be smart about where to save
	var outFile string
	if strings.HasSuffix(*out, ".js") {
		outFile = *out
	} else if strings.HasSuffix(*out, "/") {
		outFile = *out + "models.js"
	} else {
		outFile = *out + "/models.js"
	}

	fi, err := os.Create(outFile)
	if err != nil {
		log.WithError(err).Fatalln("error creating file")
	}
	defer fi.Close()

	write(fi, fmt.Sprintf("//@flow\n\n// DO NOT EDIT -- automatically generated by goflow on %s\n\n", time.Now()))

	var typeCt, fieldCt int

	// Sort the base types alphabetically
	sortedBase := []string{}
	for k := range p.BaseMappings {
		sortedBase = append(sortedBase, k)
	}
	sort.Strings(sortedBase)

	// Sort the structs alphabetically
	sortedStructs := []string{}
	for k := range p.Mappings {
		sortedStructs = append(sortedStructs, k)
	}
	sort.Strings(sortedStructs)

	for _, v := range sortedBase {
		if c, ok := p.Comments[v]; ok {
			if strings.Contains(c, "// flowignore") {
				continue
			}
			comment := strings.Replace(c, "\n", "\n// ", -1)
			comment = strings.TrimSuffix(comment, `// `)
			write(fi, fmt.Sprintf("// %s", comment))
		}
		write(fi, fmt.Sprintf("export type %s = %s\n\n", p.BaseMappings[v].Name, p.BaseMappings[v].Type))
	}

	for _, v := range sortedStructs {
		if len(p.Mappings[v]) == 0 {
			continue
		}
		strict := false
		if c, ok := p.Comments[v]; ok {

			// Ignore flowignore comments
			if strings.Contains(c, "\n@flowignore\n") {
				continue
			}

			if strings.Contains(c, "\n@strict\n") {
				strict = true
			}

			comment := strings.Replace(c, "\n", "\n// ", -1)
			comment = strings.TrimSuffix(comment, `// `)
			write(fi, fmt.Sprintf("// %s", comment))
		}
		if strict {
			write(fi, fmt.Sprintf("export type %s = {|\n", v))
		} else {
			write(fi, fmt.Sprintf("export type %s = {\n", v))
		}

		for _, s := range p.Mappings[v] {
			fieldCt++
			writeStructBody(s, 0, fi)
		}
		if strict {
			write(fi, fmt.Sprint("|}\n\n"))
		} else {
			write(fi, fmt.Sprint("}\n\n"))
		}
	}

	typeCt += len(p.BaseMappings) + len(p.Mappings)
	spin.Stop()
	log.WithField("ct", typeCt).Info("converted types")
	log.WithField("ct", fieldCt).Info("converted fields")
	log.WithField("save_location", outFile).Info("saved")
	log.WithField("duration", time.Now().Sub(start)).Info("completed code generation")
}

func writeStructBody(s parse.Field, level int, fi *os.File) {
	var name, typ string
	if s.JSONTags.Flow.Name != "" {
		name = s.JSONTags.Flow.Name
	} else {
		name = s.JSONTags.JSON
	}
	if s.JSONTags.Flow.Type != "" {
		typ = s.JSONTags.Flow.Type
	} else {
		typ = s.Type
	}
	if s.Type == "struct" {
		// Indent the struct key
		for i := 0; i < level; i++ {
			write(fi, "\t")
		}
		write(fi, fmt.Sprintf("\t%s: object {\n", name))
		for i := range s.Children {
			writeStructBody(s.Children[i], level+1, fi)
		}
		for i := level; i > 0; i-- {
			// Indent the ending struct braces
			for j := level; j > 0; j-- {
				write(fi, "\t")
			}
		}
		write(fi, "\t},\n")
		return
	}

	writeLine(name, typ, s.Comment, level, fi)

}

func writeLine(name, t, comment string, level int, fi *os.File) {
	for i := 0; i < level; i++ {
		// Indent each line the amount of levels it is deep
		write(fi, "\t")
	}
	if comment != "" {
		write(fi, fmt.Sprintf("\t%s: %s,\t//%s", name, t, comment))
	} else {
		write(fi, fmt.Sprintf("\t%s: %s,\n", name, t))
	}
}

func write(fi *os.File, line string) {
	if _, err := fi.WriteString(line); err != nil {
		log.WithError(err).Fatalln("error writing")
	}
}
